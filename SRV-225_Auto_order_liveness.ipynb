{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Data analysis / Data processing\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "from datetime import time, timedelta, datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Maths & Stats\n",
    "import math \n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "import AB_library\n",
    "\n",
    "# System library\n",
    "import os\n",
    "import ipywidgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "import openpyxl\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "# Data connection\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "\n",
    "# Useful functions\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {date} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for date in daterange:\n",
    "        counter+=1\n",
    "        print(f\"{counter}) Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df\n",
    "\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(\n",
    "        html_str.replace('table','table style=\"display:inline\"'), \n",
    "        raw=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ztest_proportion(\n",
    "    df: pd.DataFrame,\n",
    "    metric_col: str,\n",
    "    ab_group_col: str,\n",
    "    pairs_list: List[Tuple[int, int]] = [(0, 1)],\n",
    "    corrected_ci: float = 0.95,\n",
    "    flag_notation: bool = False\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"Perform proportion tests between two groups.\"\"\"\n",
    "    res_table = pd.DataFrame()\n",
    "    tail = (1 + corrected_ci) / 2\n",
    "    for pair in pairs_list:\n",
    "        num0 = df[df[ab_group_col] == pair[0]][metric_col].sum()\n",
    "        denom0 = df[df[ab_group_col] == pair[0]][metric_col].count()\n",
    "        num1 = df[df[ab_group_col] == pair[1]][metric_col].sum()\n",
    "        denom1 = df[df[ab_group_col] == pair[1]][metric_col].count()\n",
    "        p0 = num0 / denom0\n",
    "        p1 = num1 / denom1\n",
    "        std0 = df[df[ab_group_col] == pair[0]][metric_col].std()\n",
    "        std1 = df[df[ab_group_col] == pair[1]][metric_col].std()\n",
    "        r = test_proportions_2indep(\n",
    "            num0, denom0,\n",
    "            num1, denom1,\n",
    "            value=0,\n",
    "            method='wald',\n",
    "            compare='diff',\n",
    "            alternative='two-sided',\n",
    "            return_results = True\n",
    "        )\n",
    "        se = np.sqrt(r.variance)\n",
    "        delta = p1 - p0\n",
    "        delta_per = (p1 / p0 - 1) * 100\n",
    "        lb = delta - stats.norm.ppf(tail) * se\n",
    "        ub = delta + stats.norm.ppf(tail) * se\n",
    "        lb_per = lb * 100 / p0\n",
    "        ub_per = ub * 100 / p0\n",
    "        \n",
    "        if flag_notation == True:\n",
    "            print(f'\\nComparison between groups: {pair[0]} and {pair[1]}')\n",
    "            print(f'statistic: {r.statistic}, pvalue: {r.pvalue}')\n",
    "            print(f'delta = {delta}')\n",
    "            print(f'delta,% = {delta_per}%')\n",
    "            print(f'Confidence interval for delta: ({lb}, {ub})')\n",
    "            print(f'Confidence interval for delta, %: ({lb_per}, {ub_per})')\n",
    "\n",
    "        result = pd.DataFrame(\n",
    "            np.array([metric_col, denom0, denom1, pair[0], pair[1], r.statistic, r.pvalue, p0, p1, delta, delta_per, lb, ub, lb_per, ub_per]).reshape(1, -1),\n",
    "            columns=['metric_name', \n",
    "                     'group0_sample_size', \n",
    "                     'group1_sample_size', \n",
    "                     'group0', \n",
    "                     'group1', \n",
    "                     'statistic', \n",
    "                     'pvalue', \n",
    "                     'mean0', \n",
    "                     'mean1', \n",
    "                     'diff_mean', \n",
    "                     'diff_mean_%', \n",
    "                     'lower_boundary', \n",
    "                     'upper_boundary', \n",
    "                     'lower_boundary_%', \n",
    "                     'upper_boundary_%',]\n",
    "        )\n",
    "        res_table = pd.concat([res_table, result])\n",
    "\n",
    "        for column in res_table.columns[5:]:\n",
    "            res_table[column] = res_table[column].astype(float)\n",
    "        \n",
    "    return res_table\n",
    "\n",
    "def ttest(\n",
    "    df: pd.DataFrame,\n",
    "    metric_col: str,\n",
    "    ab_group_col: str,\n",
    "    pairs_list: List[Tuple[int, int]] = [(0, 1)],\n",
    "    corrected_ci: float = 0.95,\n",
    "    flag_notation: bool = False\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"Perform t-tests between two groups.\"\"\"\n",
    "    res_table = pd.DataFrame()\n",
    "    tail = (1 + corrected_ci) / 2\n",
    "    for pair in pairs_list:\n",
    "        sample0 = df.loc[df[ab_group_col] == pair[0], metric_col]\n",
    "        sample1 = df.loc[df[ab_group_col] == pair[1], metric_col]\n",
    "        m0 = sample0.mean()\n",
    "        m1 = sample1.mean()\n",
    "        v0 = sample0.std()**2\n",
    "        v1 = sample1.std()**2\n",
    "        n0 = len(sample0)\n",
    "        n1 = len(sample1)\n",
    "        t, pvalue, df_ = ws.ttest_ind(\n",
    "            sample0,\n",
    "            sample1,\n",
    "            alternative='two-sided',\n",
    "            usevar='unequal'\n",
    "        )\n",
    "        se = np.sqrt(v0 / n0 + v1 / n1)\n",
    "        delta = m1 - m0\n",
    "        delta_per = (m1 / m0 - 1) * 100\n",
    "        lb = delta - stats.t.ppf(tail, df_) * se\n",
    "        ub = delta + stats.t.ppf(tail, df_) * se\n",
    "        lb_per = lb * 100 / m0\n",
    "        ub_per = ub * 100 / m0\n",
    "        \n",
    "        if flag_notation == True:\n",
    "            print(f'\\nComparison between groups: {pair[0]} and {pair[1]}')\n",
    "            print(f't-statistic: {t}, pvalue: {pvalue}, df: {df_}')\n",
    "            print(f'delta = {delta}')\n",
    "            print(f'delta,% = {delta_per}%')\n",
    "            print(f'Confidence interval for delta: ({lb}, {ub})')\n",
    "            print(f'Confidence interval for delta, %: ({lb_per}, {ub_per})')\n",
    "\n",
    "        result = pd.DataFrame(\n",
    "            np.array([metric_col, n0, n1, pair[0], pair[1], t, \n",
    "            # df_, \n",
    "            pvalue, m0, m1, delta, delta_per, lb, ub, lb_per, ub_per]).reshape(1, -1),\n",
    "            columns=['metric_name', \n",
    "                     'group0_sample_size', \n",
    "                     'group1_sample_size',\n",
    "                     'group0', \n",
    "                     'group1', \n",
    "                     'statistic', \n",
    "                    #  'df', \n",
    "                     'pvalue', \n",
    "                     'mean0', \n",
    "                     'mean1', \n",
    "                     'diff_mean', \n",
    "                     'diff_mean_%', \n",
    "                     'lower_boundary', \n",
    "                     'upper_boundary', \n",
    "                     'lower_boundary_%', \n",
    "                     'upper_boundary_%']\n",
    "        )\n",
    "        res_table = pd.concat([res_table, result])\n",
    "    \n",
    "    for column in res_table.columns[5:]:\n",
    "        res_table[column] = res_table[column].astype(float)\n",
    "\n",
    "    return res_table\n",
    "\n",
    "def method_benjamini_hochberg(\n",
    "    pvalues: np.ndarray,\n",
    "    alpha: float = 0.05\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"Apply the Benjamini-Hochberg procedure for multiple hypothesis testing.\"\"\"\n",
    "    m = len(pvalues)\n",
    "    array_alpha = np.arange(1, m + 1) * alpha / m\n",
    "    sorted_pvalue_indexes = np.argsort(pvalues)\n",
    "    res = np.zeros(m)\n",
    "    for idx, pvalue_index in enumerate(sorted_pvalue_indexes):\n",
    "        pvalue = pvalues[pvalue_index]\n",
    "        alpha_ = array_alpha[idx]\n",
    "        if pvalue <= alpha_:\n",
    "            res[pvalue_index] = 1\n",
    "        else:\n",
    "            break\n",
    "    return res.astype(int)\n",
    "\n",
    "# Shapiro-Wilk test & Distributions\n",
    "def check_normality(df, group_column, value_column):\n",
    "    groups = df[group_column].unique()\n",
    "\n",
    "    for group in groups:\n",
    "        group_data = df[df[group_column] == group][value_column].dropna() \n",
    "        stat, p = stats.shapiro(group_data)\n",
    "        print(f'Group {group}: W={stat:.4f}, p-value={p:.4f}')\n",
    "        if p > 0.05:\n",
    "            print(f'Group {group}, Metric: {value_column}: Data is normal distributed')\n",
    "        else:\n",
    "            print(f'Group {group}, Metric: {value_column}: Data is not normal distributed')\n",
    "\n",
    "def plot_distribution(df, group_column, value_column):\n",
    "\n",
    "    groups = df[group_column].unique()\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10), gridspec_kw={'height_ratios': [1, 1.5]})\n",
    "\n",
    "    sns.histplot(data=df, x=value_column, hue=group_column, kde=True, bins=30, alpha=0.4, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"Graph + KDE\")\n",
    "    axes[0, 0].set_xlabel(value_column)\n",
    "    axes[0, 0].set_ylabel(\"Frequence\")\n",
    "\n",
    "    sns.boxplot(data=df, x=group_column, y=value_column, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title(\"Boxplot grouped\")\n",
    "    axes[0, 1].set_xlabel(group_column)\n",
    "    axes[0, 1].set_ylabel(value_column)\n",
    "\n",
    "    sns.histplot(df[df[group_column] == groups[0]][value_column], bins=30, kde=True, color='blue', alpha=0.5, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(f'Hist for the {groups[0]}')\n",
    "    axes[1, 0].set_xlabel(value_column)\n",
    "    axes[1, 0].set_ylabel(\"frequence\")\n",
    "\n",
    "    sns.histplot(df[df[group_column] == groups[1]][value_column], bins=30, kde=True, color='orange', alpha=0.5, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(f'Hist for the {groups[1]}')\n",
    "    axes[1, 1].set_xlabel(value_column)\n",
    "    axes[1, 1].set_ylabel(\"Frequence\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Levene's & Bartlet's test\n",
    "def levene(df, indicator, metric):\n",
    "    w_stats, p_value = st.levene(\n",
    "        df[df['group_name'] == 0][indicator], \n",
    "        df[df['group_name'] == 1][indicator],\n",
    "                            center=metric)\n",
    "    \n",
    "    alpha = 0.05\n",
    "    \n",
    "    if p_value > alpha:\n",
    "        print(f\"Variance are from the same population on {metric}\")\n",
    "    else:\n",
    "        print(f\"Variance are from the different population on {metric}\")\n",
    "    \n",
    "# Cohen's D\n",
    "def cohens_d(df, metric):\n",
    "    group1 = df[df['group_name']==1][metric]\n",
    "    group2 = df[df['group_name']==0][metric]\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "     \n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1 ** 2 + (n2 - 1) * std2 ** 2) / (n1 + n2 - 2))\n",
    "     \n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "     \n",
    "    # if d <= 0.3:\n",
    "    #     print(f'Small effect: d ≈ 0-0.3 ({d:.3f})')\n",
    "    # elif 0.31 <= d <= 0.8:\n",
    "    #     print(f'Medium effect: d ≈ 0.3-0.8 ({d:.3f})')\n",
    "    # elif 0.81 <= d <= 1:\n",
    "    #     print(f'Large effect: d ≈ 0.8-1 ({d:.3f})')\n",
    "\n",
    "    return d\n",
    "\n",
    "# SRM\n",
    "def srm(df):\n",
    "    srm_df = pd.DataFrame()\n",
    "\n",
    "    for city in df['city_name'].unique():\n",
    "        \n",
    "        observed = [\n",
    "            (df.query(f'group_name == 0 and city_name == \"{city}\"')['user_id'].count()), \n",
    "            (df.query(f'group_name == 1 and city_name == \"{city}\"')['user_id'].count())\n",
    "            ]\n",
    "\n",
    "        total_traffic = sum(observed)\n",
    "\n",
    "        expected = [total_traffic/2, total_traffic/2]\n",
    "\n",
    "        chi = st.chisquare(observed, f_exp = expected)\n",
    "\n",
    "        if chi[1] < 0.01:\n",
    "            conclusion = \"Sample ratio mismatch (SRM) may be present\"\n",
    "        else:\n",
    "            conclusion = \"Sample ratio mismatch (SRM) probably not present\"\n",
    "            print(f\"{city}, {chi[1]}\")\n",
    "\n",
    "        \n",
    "        new_srm_df = pd.DataFrame(\n",
    "            [[city, observed, total_traffic, expected, round(chi[1], 3), conclusion]], \n",
    "            columns=['city_name',  'sample_sizes', 'total_size', 'expected_sizes', 'chi_value', 'conclusion']\n",
    "            )\n",
    "\n",
    "        srm_df = pd.concat([srm_df, new_srm_df]).sort_values(['city_name', 'total_size'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return srm_df\n",
    "\n",
    "# Calcualting the significance by cities\n",
    "def calcualate_result(df_cr, df_abs):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    for city in df_cr['city_name'].unique():\n",
    "\n",
    "        absolute_values_keys_result = df_abs[df_abs['city_name']==f'{city}'].copy()\n",
    "\n",
    "        cr_df = ztest_proportion(df_cr[df_cr['city_name']==f'{city}'], 'has_ride', 'group_name')\n",
    "        cr_df['metric'] = 'Conversion'\n",
    "        cr_df['cohen_d'] = cohens_d(df_cr[df_cr['city_name']==f'{city}'], 'has_ride')\n",
    "\n",
    "        rides_df = ttest(absolute_values_keys_result, 'rides', 'group_name')\n",
    "        rides_df['metric'] = 'Quantitive'\n",
    "        rides_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'rides')\n",
    "\n",
    "        gmv_df = ttest(absolute_values_keys_result, 'gmv', 'group_name')\n",
    "        gmv_df['metric'] = 'Quantitive'\n",
    "        gmv_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'gmv')\n",
    "\n",
    "        orders_df = ttest(absolute_values_keys_result, 'orders', 'group_name')\n",
    "        orders_df['metric'] = 'Quantitive'\n",
    "        orders_df['cohen_d'] = cohens_d(absolute_values_keys_result, 'orders')\n",
    "\n",
    "        df_total = pd.concat([cr_df, rides_df, gmv_df, orders_df])\n",
    "\n",
    "        df_total['region'] = city\n",
    "        df_total['segment'] = 'By city'\n",
    "        df_total['significance'] = (df_total['pvalue']<0.05)*1\n",
    "        df_total['corrected_pvalue'] = method_benjamini_hochberg(df_total['pvalue'].values)\n",
    "\n",
    "        df_results = pd.concat([df_results, df_total])\n",
    "\n",
    "    total_cr_df = ztest_proportion(df_cr, 'has_ride', 'group_name')\n",
    "    total_cr_df['metric'] = 'Conversion'\n",
    "    total_cr_df['cohen_d'] = cohens_d(df_cr, 'has_ride')\n",
    "\n",
    "    total_rides_df = ttest(df_abs, 'rides', 'group_name')\n",
    "    total_rides_df['metric'] = 'Quantitive'\n",
    "    total_rides_df['cohen_d'] = cohens_d(df_abs, 'rides')\n",
    "\n",
    "    total_gmv_df = ttest(df_abs, 'gmv', 'group_name')\n",
    "    total_gmv_df['metric'] = 'Quantitive'\n",
    "    total_gmv_df['cohen_d'] = cohens_d(df_abs, 'gmv')\n",
    "\n",
    "    total_orders_df = ttest(df_abs, 'orders', 'group_name')\n",
    "    total_orders_df['metric'] = 'Quantitive'\n",
    "    total_orders_df['cohen_d'] = cohens_d(df_abs, 'orders')\n",
    "\n",
    "\n",
    "    total_total_df = pd.concat([total_cr_df, total_rides_df, total_gmv_df, total_orders_df])\n",
    "    total_total_df['region'] = 'All'\n",
    "    total_total_df['segment'] = 'Total'\n",
    "    total_total_df['significance'] = (df_total['pvalue']<0.05)*1\n",
    "    total_total_df['corrected_pvalue'] = method_benjamini_hochberg(df_total['pvalue'].values)\n",
    "\n",
    "    df_results = pd.concat([df_results, total_total_df])\n",
    "\n",
    "    df_results\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design of experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDE & Period calculating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the results. Summarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pulling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the key statistics over the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the test for significance calculating"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
