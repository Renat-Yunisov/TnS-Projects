{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "from datetime import time, timedelta, datetime\n",
    "import math \n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.stats as st\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display_html\n",
    "import os\n",
    "import ipywidgets\n",
    "import statsmodels.stats.weightstats as sw\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "from google.cloud import bigquery\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import statsmodels.stats.weightstats as ws\n",
    "import openpyxl\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "from ambrosia.designer import Designer, design, load_from_config\n",
    "\n",
    "# df[\"Week\"] = df[\"Date\"].dt.to_period(\"W\").dt.to_timestamp()\n",
    "\n",
    "bigquery_client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "def cycle_sql(start, end, query, weeks=False):\n",
    "    \"\"\"\n",
    "    You have to use {day} in your script to add cycle date into this backets\n",
    "    \"\"\"\n",
    "    date_start = datetime.strptime(start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    if weeks == False:\n",
    "        daterange = [(date_start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days)+1)]\n",
    "    else:\n",
    "        daterange = [(date_start + timedelta(weeks=x)).strftime('%Y-%m-%d') for x in range(((date_end-date_start).days//7)+1)] # weeks dividing days by 7\n",
    "\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    for date in daterange:\n",
    "        print(f\"Uploading - {date}:\", datetime.today().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        script = query.format(date = date)\n",
    "        df_cycle = bigquery_client.query(script).to_dataframe()\n",
    "        if df_cycle.empty == True:\n",
    "            print('Dataframe is empty')\n",
    "        total_df = pd.concat([df_cycle, total_df])\n",
    "    return total_df\n",
    "\n",
    "def read_bq(query, project='analytics-dev-333113'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    query_job = client.query(query)\n",
    "    result_df = query_job.to_dataframe()\n",
    "    return result_df\n",
    "\n",
    "def writing_excel(name:str, dataset1=None, dataset2=None, dataset3=None, dataset4=None):\n",
    "    with pd.ExcelWriter(f\"{name}.xlsx\") as writer:\n",
    "   \n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "\n",
    "        if dataset1 is not None:\n",
    "            if dataset2 is not None:\n",
    "                if dataset3 is not None:\n",
    "                    if dataset4 is not None:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                          )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                          )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                          )\n",
    "                        dataset4.to_excel(writer, sheet_name=f\"4-{name}\", \n",
    "                                        #   index=False\n",
    "                                          )\n",
    "                    else:\n",
    "                        dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                        #   index=False\n",
    "                                          )\n",
    "                        dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                        #   index=False\n",
    "                                          )\n",
    "                        dataset3.to_excel(writer, sheet_name=f\"3-{name}\", \n",
    "                                        #   index=False\n",
    "                                          )\n",
    "                else:\n",
    "                    dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                    #   index=False\n",
    "                                      )\n",
    "                    dataset2.to_excel(writer, sheet_name=f\"2-{name}\", \n",
    "                                    #   index=False\n",
    "                                      )\n",
    "            else:\n",
    "                dataset1.to_excel(writer, sheet_name=f\"1-{name}\", \n",
    "                                #   index=False\n",
    "                                  )\n",
    "\n",
    "        print('DataFrame is written to Excel File successfully.')\n",
    "\n",
    "def get_minimal_determinable_effect(std, sample_size, alpha, beta):\n",
    "    t_alpha = norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    t_beta = norm.ppf(1 - beta, loc=0, scale=1)\n",
    "    disp_sum_sqrt = (2 * (std ** 2)) ** 0.5\n",
    "    mde = (t_alpha + t_beta) * disp_sum_sqrt / np.sqrt(sample_size)\n",
    "    return mde\n",
    "\n",
    "def get_sample_size_abs(epsilon, std, alpha, beta):\n",
    "    t_alpha = norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    t_beta = norm.ppf(1 - beta, loc=0, scale=1)\n",
    "    z_scores_sum_squared = (t_alpha + t_beta) ** 2\n",
    "    sample_size = int(\n",
    "        np.ceil(\n",
    "            z_scores_sum_squared * (2 * std ** 2) / (epsilon ** 2)\n",
    "        )\n",
    "    )\n",
    "    return sample_size\n",
    "\n",
    "def get_ttest_pvalue(metrics_a_group, metrics_b_group):\n",
    "    _, pvalue = stats.ttest_ind(metrics_a_group, metrics_b_group)\n",
    "    return pvalue\n",
    "\n",
    "def estimate_errors(group_generator, effect_add_type, effect, alpha):\n",
    "    pvalues_aa = []\n",
    "    pvalues_ab = []\n",
    "    for a_metric_values, b_metric_values in group_generator:\n",
    "        pvalues_aa.append(get_ttest_pvalue(a_metric_values, b_metric_values))\n",
    "        b_metric_values_with_effect = b_metric_values.copy()\n",
    "        if effect_add_type == 'all_percent':\n",
    "            b_metric_values_with_effect *= 1 + effect / 100\n",
    "        elif effect_add_type == 'all_const':\n",
    "            b_metric_values_with_effect += b_metric_values_with_effect.mean() * effect / 100\n",
    "        pvalues_ab.append(get_ttest_pvalue(a_metric_values, b_metric_values_with_effect))\n",
    "    first_type_error = np.mean(np.array(pvalues_aa) < alpha)\n",
    "    second_type_error = np.mean(np.array(pvalues_ab) >= alpha)\n",
    "    return pvalues_aa, pvalues_ab, first_type_error, second_type_error\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
